{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codedetails import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example, we need just two topics: alt.atheism, soc.religion.christianity\n",
    "set_topics(['alt.atheism', 'soc.religion.christian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'train' data rows for atheism and christianity categories\n",
    "fetch_and_load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jkellett@netcom.com (Joe Kellett)\n",
      "Subject: Re: Hell\n",
      "Organization: Netcom\n",
      "Lines: 17\n",
      "\n",
      "In article <Apr.10.05.33.44.1993.14422@athos.rutgers.edu> mcovingt@aisun3.ai.uga.edu (Michael Covington) writes:\n",
      ">\n",
      ">In a short poem (\"God in His mercy made / the fixed pains of Hell\"),\n",
      ">C. S. Lewis expresses an idea that I'm sure was current among others,\n",
      ">but I haven't be able to find its source:\n",
      ">\n",
      ">that even Hell is an expression of mercy, because God limits the amount\n",
      ">of separation from Him, and hence the amount of agony, that one can\n",
      ">achieve.\n",
      ">\n",
      "\n",
      "I have also heard it called an expression of mercy, because Heaven would be\n",
      "far more agonizing for those who had rejected God.\n",
      "\n",
      "-- \n",
      "Joe Kellett\n",
      "jkellett@netcom.com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_one_sample_from_training_set (idx=49) # idx = 49 is a random selection from entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'test' data rows for atheism and christianity categories\n",
    "fetch_and_load_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_structured_data_form ()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3fa830e28e2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsgroups_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\AI-United\\AiU2\\GoldStandard\\exercises\\LIME-Explanations-for-TEXT-Classifier\\codedetails.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_vectors, test_vectors, newsgroups_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# Provide train data and train labels (target/outcome)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsgroups_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_f1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "rf = train_model (train_vectors, test_vectors, newsgroups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_f1_score (rf, test_vectors, newsgroups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random sample input \n",
    "idx = 80\n",
    "print_test_sample (idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LIME to explain/test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_lime_explanations_for_text_sample (idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The words from the newsletter Header/footer fields have also contributed to predicted category, whereas they should not !!\n",
    "\n",
    "# Lets fix the sample text by omiting Header, footer, quote fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train_fixed = fetch_20newsgroups (subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "newsgroups_test_fixed = fetch_20newsgroups (subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "train_vectors_fixed = vectorizer.transform (newsgroups_train_fixed.data)\n",
    "test_vectors_fixed = vectorizer.transform (newsgroups_test_fixed.data)\n",
    "\n",
    "# Use Random forest for training the model\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors_fixed, newsgroups_train_fixed.target)              \n",
    "\n",
    "print (newsgroups_test_fixed.data [idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is trained, make predictions on test data using the trained model.\n",
    "pred = rf.predict(test_vectors_fixed)\n",
    "\n",
    "# Compute F-score i.e., quality metric showing the accuracy level.\n",
    "print (\"\\nF1 score (after fixing data): \", sklearn.metrics.f1_score(newsgroups_test_fixed.target, pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After removing spurious features, predicted probabilities (atheism, christian) by trained model\n",
    "print(\"After removing fields, probabilities: ['aethism': %.2f %%, 'christianity': %.2f %%]\" \n",
    "      %(rf.predict_proba(test_vectors_fixed[idx])[0,0]*100,\n",
    "        rf.predict_proba(test_vectors_fixed[idx])[0,1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(newsgroups_test_fixed.data[idx],\n",
    "                                 c.predict_proba, num_features=6)\n",
    "# After removing spurious features, LIME explanations\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
